{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=ltr align=center>\n",
    "    <font color=0F5298 size=7>Neurosymbolic VQA Program Generator</font><br>\n",
    "    <br/>\n",
    "    <font color=4169E1 size=5>Part 2: REINFORCE Fine-Tuning</font><br>\n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Goal: REINFORCE Fine-Tuning**\n",
    "\n",
    "Supervised learning (Part 1) has a major weakness: **exposure bias**.\n",
    "\n",
    "1.  During training, it *always* sees the correct ground-truth program prefix (teacher forcing).\n",
    "2.  During inference, it must generate the program based on its *own* previous predictions. If it makes one mistake, the error can cascade, leading to a completely wrong program.\n",
    "\n",
    "**Solution:** Use Reinforcement Learning (RL) to fine-tune the model. Instead of punishing the model for *syntax* (i.e., not matching the ground-truth program), we reward it for *semantics* (i.e., generating a program that produces the **correct final answer**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **The REINFORCE Algorithm**\n",
    "\n",
    "We use a simple policy gradient algorithm called **REINFORCE**.\n",
    "\n",
    "1.  **Policy ($\\pi_\\theta$)**: Our Seq2Seq model. It defines a probability distribution over programs given a question.\n",
    "2.  **Action ($a$)**: The program generated by *sampling* from the model's output distribution.\n",
    "3.  **Reward ($R$)**: We run the sampled program through the symbolic `ClevrExecutor`. \n",
    "    - **`R = 1.0`** if `executor_answer == ground_truth_answer`\n",
    "    - **`R = 0.0`** otherwise\n",
    "4.  **Baseline ($b$)**: To reduce variance, we use a baseline. This is a moving average of past rewards. \n",
    "5.  **Advantage ($A$)**: `A = R - b`. \n",
    "    - If `A > 0` (the program worked better than average), we *increase* the probability of generating it.\n",
    "    - If `A < 0` (the program worked worse than average), we *decrease* its probability.\n",
    "\n",
    "The loss function is: \n",
    "\n",
    "$$L = - \\sum_{t} \\log \\pi_\\theta(a_t | s) \\cdot A$$\n",
    "\n",
    "This logic is implemented in `src/training/train_reinforce.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# Import config for file paths\n",
    "import src.config as config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy 1: **Fine-Tune LSTM with REINFORCE**\n",
    "\n",
    "We load the weights from our best *supervised* LSTM model and use them as the starting point for fine-tuning. This is **critical**â€”training from scratch with RL would be extremely difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Starting REINFORCE Fine-Tuning for LSTM ---\")\n",
    "!python ../scripts/train.py \\\n",
    "    --model_type lstm \\\n",
    "    --train_mode reinforce \\\n",
    "    --load_model ../models/supervised_lstm.pth \\\n",
    "    --model_save_path ../models/reinforce_lstm.pth \\\n",
    "    --num_iters 50000 \\\n",
    "    --learning_rate 1e-5 \\\n",
    "    --batch_size 64\n",
    "\n",
    "print(\"--- LSTM REINFORCE Training Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy 2: **Fine-Tune Transformer with REINFORCE**\n",
    "\n",
    "Similarly, we load the supervised Transformer as our starting policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Starting REINFORCE Fine-Tuning for Transformer ---\")\n",
    "!python ../scripts/train.py \\\n",
    "    --model_type transformer \\\n",
    "    --train_mode reinforce \\\n",
    "    --load_model ../models/supervised_transformer.pth \\\n",
    "    --model_save_path ../models/reinforce_transformer.pth \\\n",
    "    --num_iters 50000 \\\n",
    "    --learning_rate 1e-5 \\\n",
    "    --batch_size 64\n",
    "\n",
    "print(\"--- Transformer REINFORCE Training Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: **Analyze Results**\n",
    "\n",
    "Let's parse the log file again, this time comparing the supervised and REINFORCE-tuned models. We hope to see that REINFORCE improves the final validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import src.config as config\n",
    "\n",
    "# Note: This cell assumes the first code cell in this notebook was run to add the project root to sys.path\n",
    "\n",
    "def parse_validation_accuracy(log_file_path, run_name):\n",
    "    \"\"\"A simple parser to extract validation accuracies from the log file.\"\"\"\n",
    "    accuracies = []\n",
    "    run_started = False\n",
    "    start_regex = re.compile(f\"Starting training run: {re.escape(run_name)}\")\n",
    "    acc_regex = re.compile(r\"Validation Accuracy: (\\d+\\.\\d+)%\")\n",
    "    other_run_regex = re.compile(r\"Starting training run:\")\n",
    "\n",
    "    try:\n",
    "        with open(log_file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                if not run_started:\n",
    "                    if start_regex.search(line):\n",
    "                        run_started = True\n",
    "                else:\n",
    "                    if other_run_regex.search(line) and not start_regex.search(line):\n",
    "                        break\n",
    "                    match = acc_regex.search(line)\n",
    "                    if match:\n",
    "                        accuracies.append(float(match.group(1)))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Log file not found at: {log_file_path}\")\n",
    "        return []\n",
    "    \n",
    "    return accuracies\n",
    "\n",
    "# --- Parse Logs ---\n",
    "log_path = os.path.join(config.LOG_DIR, \"program_generator.log\")\n",
    "\n",
    "lstm_sup = parse_validation_accuracy(log_path, \"lstm (supervised)\")\n",
    "lstm_rl = parse_validation_accuracy(log_path, \"lstm (reinforce)\")\n",
    "trans_sup = parse_validation_accuracy(log_path, \"transformer (supervised)\")\n",
    "trans_rl = parse_validation_accuracy(log_path, \"transformer (reinforce)\")\n",
    "\n",
    "print(f\"Found {len(lstm_sup)} supervised LSTM points.\")\n",
    "print(f\"Found {len(lstm_rl)} REINFORCE LSTM points.\")\n",
    "print(f\"Found {len(trans_sup)} supervised Transformer points.\")\n",
    "print(f\"Found {len(trans_rl)} REINFORCE Transformer points.\")\n",
    "\n",
    "# --- Plot Results ---\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6), sharey=True)\n",
    "\n",
    "fig.suptitle('Supervised vs. REINFORCE Fine-Tuning Validation Accuracy')\n",
    "\n",
    "# LSTM Plot\n",
    "ax1.set_title(\"LSTM Model\")\n",
    "ax1.set_xlabel(f\"Validation Step (x {config.VAL_INTERVAL} iterations)\")\n",
    "ax1.set_ylabel(\"Program Execution Accuracy (%)\")\n",
    "if lstm_sup:\n",
    "    ax1.plot(lstm_sup, label=\"Supervised\", marker='o', linestyle='--')\n",
    "if lstm_rl:\n",
    "    ax1.plot(lstm_rl, label=\"REINFORCE\", marker='o')\n",
    "ax1.legend()\n",
    "ax1.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Transformer Plot\n",
    "ax2.set_title(\"Transformer Model\")\n",
    "ax2.set_xlabel(f\"Validation Step (x {config.VAL_INTERVAL} iterations)\")\n",
    "if trans_sup:\n",
    "    ax2.plot(trans_sup, label=\"Supervised\", marker='x', linestyle='--')\n",
    "if trans_rl:\n",
    "    ax2.plot(trans_rl, label=\"REINFORCE\", marker='x')\n",
    "ax2.legend()\n",
    "ax2.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
